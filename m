Return-Path: <linux-kernel+bounces-228479-lists+linux-kernel=lfdr.de@vger.kernel.org>
X-Original-To: lists+linux-kernel@lfdr.de
Delivered-To: lists+linux-kernel@lfdr.de
Received: from sy.mirrors.kernel.org (sy.mirrors.kernel.org [IPv6:2604:1380:40f1:3f00::1])
	by mail.lfdr.de (Postfix) with ESMTPS id 815DD916078
	for <lists+linux-kernel@lfdr.de>; Tue, 25 Jun 2024 09:54:17 +0200 (CEST)
Received: from smtp.subspace.kernel.org (wormhole.subspace.kernel.org [52.25.139.140])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by sy.mirrors.kernel.org (Postfix) with ESMTPS id EDA56B224DC
	for <lists+linux-kernel@lfdr.de>; Tue, 25 Jun 2024 07:54:14 +0000 (UTC)
Received: from localhost.localdomain (localhost.localdomain [127.0.0.1])
	by smtp.subspace.kernel.org (Postfix) with ESMTP id C269B147C98;
	Tue, 25 Jun 2024 07:53:55 +0000 (UTC)
Authentication-Results: smtp.subspace.kernel.org;
	dkim=pass (2048-bit key) header.d=kernel.org header.i=@kernel.org header.b="PL/w650C"
Received: from smtp.kernel.org (aws-us-west-2-korg-mail-1.web.codeaurora.org [10.30.226.201])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by smtp.subspace.kernel.org (Postfix) with ESMTPS id 01E261474C9
	for <linux-kernel@vger.kernel.org>; Tue, 25 Jun 2024 07:53:54 +0000 (UTC)
Authentication-Results: smtp.subspace.kernel.org; arc=none smtp.client-ip=10.30.226.201
ARC-Seal:i=1; a=rsa-sha256; d=subspace.kernel.org; s=arc-20240116;
	t=1719302035; cv=none; b=RWilYb6pjGi0coeivLVpKL7QVu89w16XGzbagOeE0ttBGkjWnBbSMQsk4CjDrnzUeOB36bXJArPwxJle8s7k8JXOYu3z3fT1Fv+Syx2awuUtaBSPSZ/Enwv92dgisR/up9c4vn4BVJd63SPuKvqSa5tol5bwC6V3epEURHHUSu4=
ARC-Message-Signature:i=1; a=rsa-sha256; d=subspace.kernel.org;
	s=arc-20240116; t=1719302035; c=relaxed/simple;
	bh=qaV7tmtoxM02jcliQWMUlhg2i6RVNfMsQ+ov8eHckBE=;
	h=Date:Message-ID:From:To:Cc:Subject:In-Reply-To:References:
	 MIME-Version:Content-Type; b=oa3s5vTQ70fsFqZaRRo7c/q5Kem6gxKfidapVfOkctz+gUtashCs1DMKo0LVgmoMmidh0n36t+ma8bAF35jf7gfMwyn4YZFjBTcnHLH3rZ6Fp3VnDth0lZ+9ZYVqLWPM8NewDdlC3LRTPbGC8fbqEqZhWILlqJO5xNzOQLUMaYI=
ARC-Authentication-Results:i=1; smtp.subspace.kernel.org; dkim=pass (2048-bit key) header.d=kernel.org header.i=@kernel.org header.b=PL/w650C; arc=none smtp.client-ip=10.30.226.201
Received: by smtp.kernel.org (Postfix) with ESMTPSA id 8D85EC32781;
	Tue, 25 Jun 2024 07:53:54 +0000 (UTC)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/simple; d=kernel.org;
	s=k20201202; t=1719302034;
	bh=qaV7tmtoxM02jcliQWMUlhg2i6RVNfMsQ+ov8eHckBE=;
	h=Date:From:To:Cc:Subject:In-Reply-To:References:From;
	b=PL/w650CIk20bjn5RVx3yuWhVAfm57YOwyZoslVIIo4vm7LliLy+Jnbf/iOH7i8J1
	 aQqpk9tlYgpdpNxMS/jLLk/SkANcMfCXzqBE6CicHqmkjTOJoVbAsbZd5zM9qFZe3S
	 ATThtN2cTPtihBk+edoAaDaUZ/gT2hLFzzL3X8znfGh1Y3ow3yin04Bv4Qlg1B08ZR
	 xl2Qgv1g9p9FSV80QQUOgo3P8Fj6rygwtcgw8VML7YpLwQ9c3espSitZsW9LA2pAGk
	 iacAWXQPujJ3n+p3ePtlnFxDn6lTbx4Zk+n2jKUwyMGbKhIbR+OYmvCKFQlf9RezIi
	 ImtyYKVGrZjyA==
Received: from sofa.misterjones.org ([185.219.108.64] helo=goblin-girl.misterjones.org)
	by disco-boy.misterjones.org with esmtpsa  (TLS1.3) tls TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384
	(Exim 4.95)
	(envelope-from <maz@kernel.org>)
	id 1sM0zw-0074Zr-HP;
	Tue, 25 Jun 2024 08:53:52 +0100
Date: Tue, 25 Jun 2024 08:53:52 +0100
Message-ID: <86wmmdihkf.wl-maz@kernel.org>
From: Marc Zyngier <maz@kernel.org>
To: Nianyao Tang <tangnianyao@huawei.com>
Cc: <tglx@linutronix.de>,
	<linux-arm-kernel@lists.infradead.org>,
	<linux-kernel@vger.kernel.org>,
	<guoyang2@huawei.com>,
	<wangwudi@hisilicon.com>
Subject: Re: [RESEND PATCH] irqchip/gic-v4.1: Use the ITS of the NUMA node where current  cpu is located
In-Reply-To: <20240625014019.3914240-1-tangnianyao@huawei.com>
References: <20240625014019.3914240-1-tangnianyao@huawei.com>
User-Agent: Wanderlust/2.15.9 (Almost Unreal) SEMI-EPG/1.14.7 (Harue)
 FLIM-LB/1.14.9 (=?UTF-8?B?R29qxY0=?=) APEL-LB/10.8 EasyPG/1.0.0 Emacs/29.2
 (aarch64-unknown-linux-gnu) MULE/6.0 (HANACHIRUSATO)
Precedence: bulk
X-Mailing-List: linux-kernel@vger.kernel.org
List-Id: <linux-kernel.vger.kernel.org>
List-Subscribe: <mailto:linux-kernel+subscribe@vger.kernel.org>
List-Unsubscribe: <mailto:linux-kernel+unsubscribe@vger.kernel.org>
MIME-Version: 1.0 (generated by SEMI-EPG 1.14.7 - "Harue")
Content-Type: text/plain; charset=US-ASCII
X-SA-Exim-Connect-IP: 185.219.108.64
X-SA-Exim-Rcpt-To: tangnianyao@huawei.com, tglx@linutronix.de, linux-arm-kernel@lists.infradead.org, linux-kernel@vger.kernel.org, guoyang2@huawei.com, wangwudi@hisilicon.com
X-SA-Exim-Mail-From: maz@kernel.org
X-SA-Exim-Scanned: No (on disco-boy.misterjones.org); SAEximRunCond expanded to false

On Tue, 25 Jun 2024 02:40:19 +0100,
Nianyao Tang <tangnianyao@huawei.com> wrote:
> 
> When GICv4.1 enabled, guest sending IPI use the last ITS reported.
> On multi-NUMA environment with more than one ITS, it makes IPI performance
> various from VM to VM, depending on which NUMA the VM is deployed on.
> We can use closer ITS instead of the last ITS reported.

Closer to *what*? the SGI sender? or the receiver? Something else?

> 
> Modify find_4_1_its to find the ITS of the NUMA node where current
> cpu is located and save it with per cpu variable.

But find_4_1_its() isn't only used for SGIs. Is it valid to do this
trick for all use cases?

> (There's format issues with the previous patch, resend it)

In the future, please move this sort of comment to a note after the
--- delimiter.

> 
> Signed-off-by: Nianyao Tang <tangnianyao@huawei.com>
> ---
>  drivers/irqchip/irq-gic-v3-its.c | 27 ++++++++++++++++++---------
>  1 file changed, 18 insertions(+), 9 deletions(-)
> 
> diff --git a/drivers/irqchip/irq-gic-v3-its.c b/drivers/irqchip/irq-gic-v3-its.c
> index 3c755d5dad6e..d35b42f3b2af 100644
> --- a/drivers/irqchip/irq-gic-v3-its.c
> +++ b/drivers/irqchip/irq-gic-v3-its.c
> @@ -193,6 +193,8 @@ static DEFINE_RAW_SPINLOCK(vmovp_lock);
>  
>  static DEFINE_IDA(its_vpeid_ida);
>  
> +static DEFINE_PER_CPU(struct its_node *, its_on_cpu);

I don't really get the "its_on_cpu" name. "local_its" would at least
indicate a notion being "close".

> +
>  #define gic_data_rdist()		(raw_cpu_ptr(gic_rdists->rdist))
>  #define gic_data_rdist_cpu(cpu)		(per_cpu_ptr(gic_rdists->rdist, cpu))
>  #define gic_data_rdist_rd_base()	(gic_data_rdist()->rd_base)
> @@ -4058,19 +4060,25 @@ static struct irq_chip its_vpe_irq_chip = {
>  
>  static struct its_node *find_4_1_its(void)
>  {
> -	static struct its_node *its = NULL;
> +	struct its_node *its = NULL;
> +	struct its_node *its_non_cpu_node = NULL;
> +	int cpu = smp_processor_id();
>  
> -	if (!its) {
> -		list_for_each_entry(its, &its_nodes, entry) {
> -			if (is_v4_1(its))
> -				return its;
> -		}
> +	if (per_cpu(its_on_cpu, cpu))
> +		return per_cpu(its_on_cpu, cpu);
>  
> -		/* Oops? */
> -		its = NULL;
> -	}
> +	list_for_each_entry(its, &its_nodes, entry) {
> +		if (is_v4_1(its) && its->numa_node == cpu_to_node(cpu)) {
> +			per_cpu(its_on_cpu, cpu) = its;
> +			return its;
> +		} else if (is_v4_1(its))
> +			its_non_cpu_node = its;
> +	}

Why do you consider the NUMA node instead of the ITS' own affinity?
SVPET gives you some notion of distance with the RDs, and that'd
probably be useful.

>  
> -	return its;
> +	if (!per_cpu(its_on_cpu, cpu) && its_non_cpu_node)
> +		per_cpu(its_on_cpu, cpu) = its_non_cpu_node;
> +
> +	return its_non_cpu_node;
>  }

Urgh. Mixing init and runtime is awful. Why isn't this initialised
when a CPU comes up? We already have all the infrastructure.

But the biggest question is "what sort of performance improvement does
this bring"? You give no numbers, no way to evaluate anything.

I've asked for that times and times again: if your changes are
claiming a performance improvement, please back it up. It's not that
hard.

Thanks,

	M.

-- 
Without deviation from the norm, progress is not possible.

